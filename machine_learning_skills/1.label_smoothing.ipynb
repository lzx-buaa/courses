{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "damaged-apartment",
   "metadata": {},
   "source": [
    "## Label Smoothing - Details\n",
    " - Regularization technique\n",
    " - Reduce overfitting and overconfidence\n",
    " - Formula\n",
    "     - Replaces one-hot encoding with a mixture of one-hot and the uniform distribution\n",
    "     \n",
    "$$\n",
    "    y_{LS} = (1-\\alpha) * y_{hot} + \\frac{\\alpha}{K}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "vietnamese-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "black-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth_one_hot(targets: torch.Tensor, n_classes: int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = torch.empty(size=(targets.size(0), n_classes),\n",
    "                                  device=targets.device) \\\n",
    "                .fill_(smoothing / (n_classes - 1)) \\\n",
    "                .scatter_(1, targets.data.unsqueeze(1), 1. - smoothing)\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = LabelSmoothCrossEntropyLoss._smooth_one_hot(targets, inputs.size(-1),\n",
    "                                                              self.smoothing)\n",
    "        lsm = F.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = -(targets * lsm).sum(-1)\n",
    "\n",
    "        if self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "successful-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = LabelSmoothCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "initial-valuable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.6981,  0.9529, -0.0807, -0.5213, -0.0753],\n",
       "         [ 0.8347, -1.4822, -0.0525, -0.7690,  0.4886],\n",
       "         [-1.1051,  0.3915,  0.5995,  1.0561,  0.7371]], requires_grad=True),\n",
       " tensor([1, 1, 3]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(3, 5, requires_grad=True)\n",
    "targets = torch.empty(3, dtype=torch.long).random_(5)\n",
    "inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "surface-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOOTH = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "lovely-rachel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0125"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILL_VALUE = SMOOTH/(inputs.size(-1)-1)\n",
    "FILL_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "developing-convert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0125, 0.0125, 0.0125, 0.0125, 0.0125],\n",
       "        [0.0125, 0.0125, 0.0125, 0.0125, 0.0125],\n",
       "        [0.0125, 0.0125, 0.0125, 0.0125, 0.0125]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(inputs.size()).fill_(FILL_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "spectacular-slide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0125, 0.0125, 0.9500, 0.0125, 0.0125],\n",
       "        [0.9500, 0.0125, 0.0125, 0.0125, 0.0125],\n",
       "        [0.0125, 0.0125, 0.0125, 0.0125, 0.9500]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(inputs.size()).fill_(FILL_VALUE).scatter_(1,targets.data.unsqueeze(1),1. - SMOOTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "animated-samba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0125, 0.9500, 0.0125, 0.0125, 0.0125],\n",
       "        [0.0125, 0.9500, 0.0125, 0.0125, 0.0125],\n",
       "        [0.0125, 0.0125, 0.0125, 0.9500, 0.0125]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth_targets = loss_function._smooth_one_hot(targets, inputs.size(-1), smoothing=0.05)\n",
    "smooth_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "advance-porcelain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4091, -0.7581, -1.7917, -2.2322, -1.7863],\n",
       "        [-0.8833, -3.2003, -1.7706, -2.4870, -1.2295],\n",
       "        [-3.2565, -1.7599, -1.5519, -1.0953, -1.4142]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsm = F.log_softmax(inputs, -1)\n",
    "lsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "together-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0899, 0.4686, 0.1667, 0.1073, 0.1676],\n",
       "        [0.4134, 0.0408, 0.1702, 0.0832, 0.2925],\n",
       "        [0.0385, 0.1721, 0.2118, 0.3345, 0.2431]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(inputs,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "central-advantage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4091, -0.7581, -1.7917, -2.2322, -1.7863],\n",
       "        [-0.8833, -3.2003, -1.7706, -2.4870, -1.2295],\n",
       "        [-3.2565, -1.7599, -1.5519, -1.0953, -1.4142]], grad_fn=<LogBackward>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(F.softmax(inputs,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "annual-settlement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8229, 3.1199, 1.1403], grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(smooth_targets*torch.log(F.softmax(inputs,-1))).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "painful-reality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.0831, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(smooth_targets*torch.log(F.softmax(inputs,-1))).sum(-1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "japanese-minimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6944, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(smooth_targets*torch.log(F.softmax(inputs,-1))).sum(-1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-statement",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "1. https://stackoverflow.com/questions/55681502/label-smoothing-in-pytorch  \n",
    "2. https://github.com/NingAnMe/Label-Smoothing-for-CrossEntropyLoss-PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-consultancy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
