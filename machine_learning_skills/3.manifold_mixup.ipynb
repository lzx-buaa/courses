{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f37d195-1600-4660-a19f-8e2620f74edd",
   "metadata": {},
   "source": [
    "## Key Ideas\n",
    "\n",
    "- smoother decision boundaries at multiple levels of representation\n",
    "- less confident predictions\n",
    "- more robust with adversarial examples (need a big/perceptible change in decision boundaries)\n",
    "- Manifold has 3 effects on training:\n",
    "    - smooths decision boundaries\n",
    "    - improves arrangement of hidden representation (encorages regions of low confidence)\n",
    "    - flattens representations (minimal amount of directions of variation)\n",
    "- decision boundaries are usually sharp and close to the data\n",
    "- Central message of the paper\n",
    "\n",
    "```\n",
    "Manifold Mixup improves the hidden representations and decision boundaries of neural networks at\n",
    "multiple layers.\n",
    "```\n",
    "\n",
    "- Important factors for generalization (that Manifold Mixup acts on):\n",
    "    - smoothness and margin\n",
    "    - flatten representation/compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8fe0b49-f78a-4bb6-ba5c-a3dca5fc3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "723beec8-b1ab-4023-847f-8ce1410042e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_process(out, target_reweighted, lam):\n",
    "    indices = np.random.permutation(out.size(0))\n",
    "    out = out*lam + out[indices]*(1-lam)\n",
    "    target_shuffled_onehot = target_reweighted[indices]\n",
    "    target_reweighted = target_reweighted * lam + target_shuffled_onehot * (1 - lam)\n",
    "    return out, target_reweighted\n",
    "\n",
    "\n",
    "def mixup_data(x, y, alpha):\n",
    "\n",
    "    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0.:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index,:]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ed9d2-44e6-4d4f-93d3-5f26a1c5b1f4",
   "metadata": {},
   "source": [
    "### Basic Manifold Mixup block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d62326ac-c59f-462a-94d3-86ebf782c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x, target=None, mixup_hidden = False,  mixup_alpha = 0.1, layer_mix=None):\n",
    "    if self.per_img_std:\n",
    "        x = per_image_standardization(x)\n",
    "    if mixup_hidden == True:\n",
    "        if layer_mix == None:\n",
    "            layer_mix = random.randint(0,2)\n",
    "        out = x\n",
    "        if layer_mix == 0:\n",
    "            out, y_a, y_b, lam = mixup_data(out, target, mixup_alpha)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        if layer_mix == 1:\n",
    "            out, y_a, y_b, lam = mixup_data(out, target, mixup_alpha)\n",
    "        out = self.layer2(out)\n",
    "        if layer_mix == 2:\n",
    "            out, y_a, y_b, lam = mixup_data(out, target, mixup_alpha)\n",
    "        out = self.layer3(out)\n",
    "        if layer_mix == 3:\n",
    "            out, y_a, y_b, lam = mixup_data(out, target, mixup_alpha)\n",
    "        out = self.layer4(out)\n",
    "        if layer_mix == 4:\n",
    "            out, y_a, y_b, lam = mixup_data(out, target, mixup_alpha)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        if layer_mix == 5:\n",
    "            out, y_a, y_b, lam = mixup_data(out, target, mixup_alpha)\n",
    "\n",
    "        lam = torch.tensor(lam).cuda()\n",
    "        lam = lam.repeat(y_a.size())\n",
    "        return out, y_a, y_b, lam\n",
    "\n",
    "\n",
    "    else:\n",
    "        out = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6214bf54-311b-4b95-a894-8b9bcefa1393",
   "metadata": {},
   "source": [
    "### During Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c7b4e4-f305-4c61-9e8b-12d9a904505f",
   "metadata": {},
   "source": [
    "```python\n",
    "if args.train == 'mixup':\n",
    "    output, reweighted_target = model(input_var,target_var, mixup= True, mixup_alpha = args.mixup_alpha)\n",
    "    loss = bce_loss(softmax(output), reweighted_target)#mixup_criterion(target_a, target_b, lam)\n",
    "    \"\"\"\n",
    "    mixed_input, target_a, target_b, lam = mixup_data(input, target, args.mixup_alpha)\n",
    "    input_var, mixed_input_var, target_var, target_a_var, target_b_var = Variable(input),Variable(mixed_input), Variable(target), Variable(target_a), Variable(target_b)\n",
    "\n",
    "    mixed_output = model(mixed_input_var)\n",
    "    output = model(input_var)\n",
    "\n",
    "    loss_func = mixup_criterion(target_a_var, target_b_var, lam)\n",
    "    loss = loss_func(criterion, mixed_output)\n",
    "    \"\"\"\n",
    "\n",
    "elif args.train== 'mixup_hidden':\n",
    "    output, reweighted_target = model(input_var, target_var, mixup_hidden= True, mixup_alpha = args.mixup_alpha)\n",
    "    loss = bce_loss(softmax(output), reweighted_target)#mixup_criterion(target_a, target_b, lam)\n",
    "    \"\"\"\n",
    "    input_var, target_var = Variable(input), Variable(target)\n",
    "    mixed_output, target_a, target_b, lam = model(input_var, target_var, mixup_hidden = True,  mixup_alpha = args.mixup_alpha)\n",
    "    output = model(input_var)\n",
    "\n",
    "    lam = lam[0]\n",
    "    target_a_one_hot = to_one_hot(target_a, args.num_classes)\n",
    "    target_b_one_hot = to_one_hot(target_b, args.num_classes)\n",
    "    mixed_target = target_a_one_hot * lam + target_b_one_hot * (1 - lam)\n",
    "    loss = bce_loss(softmax(output), mixed_target)\n",
    "    \"\"\"\n",
    "elif args.train == 'vanilla':\n",
    "    output, reweighted_target = model(input_var, target_var)\n",
    "    loss = bce_loss(softmax(output), reweighted_target)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d663bc-eb5a-4fbf-91ea-30af6d4b9381",
   "metadata": {},
   "source": [
    "## References\n",
    "1. [Original repo](https://github.com/vikasverma1077/manifold_mixup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75ffca-82fa-4a4b-9ed6-5e95714be58d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
